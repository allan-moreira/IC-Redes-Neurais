{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 18:41:36.167742: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-29 18:41:36.169912: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-29 18:41:36.195641: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-29 18:41:36.195667: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-29 18:41:36.196479: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-29 18:41:36.201004: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-29 18:41:36.201422: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-29 18:41:36.760112: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import fabs\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo algumas constantes\n",
    "saidas = ['DOMPRECDOMEXP', 'DOMPRECRESEXP', 'ADENSEXCDOMEXP', 'ADENSEXCRESEXP',\t'ONUSEXCDOMEXP', 'ONUSEXCRESEXP', 'COABFAMDOMEXP', 'COABFAMRESEXP']\n",
    "saidasDomicilios = ['DOMPRECDOMEXP', 'ADENSEXCDOMEXP', 'ONUSEXCDOMEXP', 'COABFAMDOMEXP']\n",
    "saidasDesidentes = ['DOMPRECRESEXP', 'ADENSEXCRESEXP', 'ONUSEXCRESEXP', 'COABFAMRESEXP']\n",
    "domiciliosPrecarios = ['DOMPRECDOMEXP']\n",
    "adensamentoExcessivo = ['ADENSEXCDOMEXP']\n",
    "onusExcessivo = ['ONUSEXCDOMEXP']\n",
    "coabtaçãoFamiliar = ['COABFAMDOMEXP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dim.1</th>\n",
       "      <th>Dim.2</th>\n",
       "      <th>Dim.3</th>\n",
       "      <th>Dim.4</th>\n",
       "      <th>Dim.5</th>\n",
       "      <th>DOMPRECDOMEXP</th>\n",
       "      <th>ADENSEXCDOMEXP</th>\n",
       "      <th>ONUSEXCDOMEXP</th>\n",
       "      <th>COABFAMDOMEXP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.255267</td>\n",
       "      <td>1.636565</td>\n",
       "      <td>-0.734032</td>\n",
       "      <td>0.249567</td>\n",
       "      <td>-0.490873</td>\n",
       "      <td>9.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>308.77</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.902284</td>\n",
       "      <td>-0.905511</td>\n",
       "      <td>-0.164092</td>\n",
       "      <td>-0.336964</td>\n",
       "      <td>-0.130283</td>\n",
       "      <td>11.43</td>\n",
       "      <td>126.68</td>\n",
       "      <td>333.07</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.514829</td>\n",
       "      <td>-0.457965</td>\n",
       "      <td>0.832445</td>\n",
       "      <td>-0.888344</td>\n",
       "      <td>0.783307</td>\n",
       "      <td>78.55</td>\n",
       "      <td>39.05</td>\n",
       "      <td>111.92</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.383952</td>\n",
       "      <td>0.202920</td>\n",
       "      <td>-0.351442</td>\n",
       "      <td>0.387851</td>\n",
       "      <td>0.348902</td>\n",
       "      <td>20.22</td>\n",
       "      <td>138.96</td>\n",
       "      <td>496.56</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.425747</td>\n",
       "      <td>0.337700</td>\n",
       "      <td>-0.249719</td>\n",
       "      <td>0.413795</td>\n",
       "      <td>0.236795</td>\n",
       "      <td>8.57</td>\n",
       "      <td>120.49</td>\n",
       "      <td>373.83</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>-2.160979</td>\n",
       "      <td>-0.774764</td>\n",
       "      <td>2.681624</td>\n",
       "      <td>-1.242698</td>\n",
       "      <td>-0.451944</td>\n",
       "      <td>22.77</td>\n",
       "      <td>88.48</td>\n",
       "      <td>52.31</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>3.486756</td>\n",
       "      <td>1.296490</td>\n",
       "      <td>0.961841</td>\n",
       "      <td>-1.467687</td>\n",
       "      <td>1.530743</td>\n",
       "      <td>19.36</td>\n",
       "      <td>64.34</td>\n",
       "      <td>313.49</td>\n",
       "      <td>881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>-3.217481</td>\n",
       "      <td>0.661316</td>\n",
       "      <td>-0.593865</td>\n",
       "      <td>0.031387</td>\n",
       "      <td>0.020535</td>\n",
       "      <td>0.00</td>\n",
       "      <td>76.27</td>\n",
       "      <td>157.44</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>-1.105044</td>\n",
       "      <td>0.994186</td>\n",
       "      <td>-0.674440</td>\n",
       "      <td>-0.233511</td>\n",
       "      <td>-0.088889</td>\n",
       "      <td>47.05</td>\n",
       "      <td>21.22</td>\n",
       "      <td>390.45</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>0.313055</td>\n",
       "      <td>-0.680279</td>\n",
       "      <td>0.117782</td>\n",
       "      <td>-0.932248</td>\n",
       "      <td>0.688112</td>\n",
       "      <td>0.00</td>\n",
       "      <td>117.92</td>\n",
       "      <td>261.08</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>903 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dim.1     Dim.2     Dim.3     Dim.4     Dim.5  DOMPRECDOMEXP  \\\n",
       "0   -4.255267  1.636565 -0.734032  0.249567 -0.490873           9.55   \n",
       "1   -0.902284 -0.905511 -0.164092 -0.336964 -0.130283          11.43   \n",
       "2   -3.514829 -0.457965  0.832445 -0.888344  0.783307          78.55   \n",
       "3    0.383952  0.202920 -0.351442  0.387851  0.348902          20.22   \n",
       "4   -1.425747  0.337700 -0.249719  0.413795  0.236795           8.57   \n",
       "..        ...       ...       ...       ...       ...            ...   \n",
       "898 -2.160979 -0.774764  2.681624 -1.242698 -0.451944          22.77   \n",
       "899  3.486756  1.296490  0.961841 -1.467687  1.530743          19.36   \n",
       "900 -3.217481  0.661316 -0.593865  0.031387  0.020535           0.00   \n",
       "901 -1.105044  0.994186 -0.674440 -0.233511 -0.088889          47.05   \n",
       "902  0.313055 -0.680279  0.117782 -0.932248  0.688112           0.00   \n",
       "\n",
       "     ADENSEXCDOMEXP  ONUSEXCDOMEXP  COABFAMDOMEXP  \n",
       "0              0.00         308.77             90  \n",
       "1            126.68         333.07            686  \n",
       "2             39.05         111.92            235  \n",
       "3            138.96         496.56            484  \n",
       "4            120.49         373.83            337  \n",
       "..              ...            ...            ...  \n",
       "898           88.48          52.31            480  \n",
       "899           64.34         313.49            881  \n",
       "900           76.27         157.44            389  \n",
       "901           21.22         390.45            670  \n",
       "902          117.92         261.08            862  \n",
       "\n",
       "[903 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importa os dados\n",
    "deficit_data_y = pd.read_excel('Banco_903_Amostras_Completo.xlsx')[saidasDomicilios]\n",
    "deficit_data_x = pd.read_excel('Dimensoes_PCA_903_Amostras.xlsx')\n",
    "\n",
    "# Concatena os dois blocos horizontalmente\n",
    "deficit_data = pd.concat([deficit_data_x, deficit_data_y], axis=1)\n",
    "\n",
    "# Exibe o banco de dados\n",
    "deficit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embaralha a ordem das amostras e divide em blocos de treino (80%) e teste (20%)\n",
    "train, test = train_test_split(deficit_data, test_size=0.2, random_state=randint(0, 100))\n",
    "\n",
    "train_x = train.drop(columns=saidasDomicilios)\n",
    "validation_x = test.drop(columns=saidasDomicilios)\n",
    "train_y = train[saidasDomicilios]\n",
    "validation_y = test[saidasDomicilios]\n",
    "\n",
    "numLines = int(validation_x.shape[0] * 0.25) #Equivalente a aproximadamente 5% do banco de dados\n",
    "\n",
    "# Separa uma parte do bloco de validação para teste\n",
    "validation_x, test_x = validation_x[:numLines], validation_x[numLines:]\n",
    "validation_y, test_y = validation_y[:numLines], validation_y[numLines:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 18:41:37.802452: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-29 18:41:37.802899: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Inicializa a rede neural\n",
    "neuralNetwork = Sequential()\n",
    "neuralNetwork.add(Dense(units = 24, activation = 'relu', input_dim = validation_x.shape[1]))\n",
    "neuralNetwork.add(Dense(units = train_y.shape[1], activation = 'linear'))\n",
    "neuralNetwork.compile(loss = 'huber', optimizer = 'rmsprop', metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 311.4898 - mae: 311.9779 - val_loss: 336.8333 - val_mae: 337.3281\n",
      "Epoch 2/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 311.1382 - mae: 311.6281 - val_loss: 336.5148 - val_mae: 337.0081\n",
      "Epoch 3/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 310.8077 - mae: 311.3004 - val_loss: 336.1866 - val_mae: 336.6781\n",
      "Epoch 4/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 310.4701 - mae: 310.9644 - val_loss: 335.8476 - val_mae: 336.3399\n",
      "Epoch 5/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 310.1224 - mae: 310.6194 - val_loss: 335.4962 - val_mae: 335.9926\n",
      "Epoch 6/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 309.7558 - mae: 310.2548 - val_loss: 335.1214 - val_mae: 335.6203\n",
      "Epoch 7/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 309.3671 - mae: 309.8666 - val_loss: 334.7211 - val_mae: 335.2208\n",
      "Epoch 8/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 308.9503 - mae: 309.4500 - val_loss: 334.2939 - val_mae: 334.7938\n",
      "Epoch 9/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 308.5032 - mae: 309.0032 - val_loss: 333.8348 - val_mae: 334.3348\n",
      "Epoch 10/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 308.0262 - mae: 308.5261 - val_loss: 333.3508 - val_mae: 333.8508\n",
      "Epoch 11/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 307.5196 - mae: 308.0194 - val_loss: 332.8259 - val_mae: 333.3259\n",
      "Epoch 12/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 306.9714 - mae: 307.4712 - val_loss: 332.2602 - val_mae: 332.7600\n",
      "Epoch 13/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 306.3972 - mae: 306.8970 - val_loss: 331.6790 - val_mae: 332.1765\n",
      "Epoch 14/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 305.7914 - mae: 306.2907 - val_loss: 331.0538 - val_mae: 331.5537\n",
      "Epoch 15/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 305.1371 - mae: 305.6365 - val_loss: 330.3824 - val_mae: 330.8824\n",
      "Epoch 16/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 304.4514 - mae: 304.9509 - val_loss: 329.6718 - val_mae: 330.1718\n",
      "Epoch 17/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 303.7284 - mae: 304.2274 - val_loss: 328.9300 - val_mae: 329.4241\n",
      "Epoch 18/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 302.9807 - mae: 303.4789 - val_loss: 328.1817 - val_mae: 328.6782\n",
      "Epoch 19/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 302.1983 - mae: 302.6968 - val_loss: 327.4123 - val_mae: 327.9121\n",
      "Epoch 20/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 301.3936 - mae: 301.8919 - val_loss: 326.6158 - val_mae: 327.1116\n",
      "Epoch 21/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 300.5602 - mae: 301.0591 - val_loss: 325.8261 - val_mae: 326.3228\n",
      "Epoch 22/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 299.7018 - mae: 300.2010 - val_loss: 324.9982 - val_mae: 325.4980\n",
      "Epoch 23/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 298.8063 - mae: 299.3052 - val_loss: 324.1447 - val_mae: 324.6447\n",
      "Epoch 24/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 297.8893 - mae: 298.3884 - val_loss: 323.2701 - val_mae: 323.7701\n",
      "Epoch 25/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 296.9421 - mae: 297.4399 - val_loss: 322.3392 - val_mae: 322.8392\n",
      "Epoch 26/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 295.9847 - mae: 296.4827 - val_loss: 321.3864 - val_mae: 321.8863\n",
      "Epoch 27/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 294.9992 - mae: 295.4982 - val_loss: 320.3989 - val_mae: 320.8929\n",
      "Epoch 28/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 293.9974 - mae: 294.4959 - val_loss: 319.4164 - val_mae: 319.9131\n",
      "Epoch 29/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 292.9795 - mae: 293.4776 - val_loss: 318.4082 - val_mae: 318.9080\n",
      "Epoch 30/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 291.9326 - mae: 292.4310 - val_loss: 317.3596 - val_mae: 317.8595\n",
      "Epoch 31/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 290.8874 - mae: 291.3857 - val_loss: 316.3404 - val_mae: 316.8379\n",
      "Epoch 32/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 289.8292 - mae: 290.3279 - val_loss: 315.2836 - val_mae: 315.7824\n",
      "Epoch 33/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 288.7408 - mae: 289.2394 - val_loss: 314.2234 - val_mae: 314.7209\n",
      "Epoch 34/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 287.6363 - mae: 288.1347 - val_loss: 313.1376 - val_mae: 313.6375\n",
      "Epoch 35/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 286.5333 - mae: 287.0316 - val_loss: 312.0435 - val_mae: 312.5407\n",
      "Epoch 36/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 285.4153 - mae: 285.9137 - val_loss: 310.9251 - val_mae: 311.4238\n",
      "Epoch 37/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 284.2642 - mae: 284.7625 - val_loss: 309.7915 - val_mae: 310.2915\n",
      "Epoch 38/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 283.0870 - mae: 283.5858 - val_loss: 308.5873 - val_mae: 309.0873\n",
      "Epoch 39/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 281.8899 - mae: 282.3883 - val_loss: 307.4018 - val_mae: 307.9016\n",
      "Epoch 40/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 280.6710 - mae: 281.1692 - val_loss: 306.1856 - val_mae: 306.6856\n",
      "Epoch 41/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 279.4525 - mae: 279.9504 - val_loss: 304.9918 - val_mae: 305.4918\n",
      "Epoch 42/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 278.2032 - mae: 278.7009 - val_loss: 303.7229 - val_mae: 304.2229\n",
      "Epoch 43/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 276.9519 - mae: 277.4505 - val_loss: 302.4793 - val_mae: 302.9793\n",
      "Epoch 44/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 275.6808 - mae: 276.1794 - val_loss: 301.2056 - val_mae: 301.7056\n",
      "Epoch 45/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 274.4130 - mae: 274.9114 - val_loss: 299.9317 - val_mae: 300.4317\n",
      "Epoch 46/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 273.1375 - mae: 273.6361 - val_loss: 298.6390 - val_mae: 299.1390\n",
      "Epoch 47/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 271.8462 - mae: 272.3446 - val_loss: 297.3111 - val_mae: 297.8111\n",
      "Epoch 48/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 270.5143 - mae: 271.0125 - val_loss: 295.9615 - val_mae: 296.4586\n",
      "Epoch 49/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 269.1701 - mae: 269.6687 - val_loss: 294.5858 - val_mae: 295.0843\n",
      "Epoch 50/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 267.8056 - mae: 268.3042 - val_loss: 293.2272 - val_mae: 293.7249\n",
      "Epoch 51/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 266.4470 - mae: 266.9455 - val_loss: 291.8203 - val_mae: 292.3195\n",
      "Epoch 52/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 265.0761 - mae: 265.5751 - val_loss: 290.3914 - val_mae: 290.8912\n",
      "Epoch 53/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 263.6635 - mae: 264.1625 - val_loss: 288.9484 - val_mae: 289.4484\n",
      "Epoch 54/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 262.2606 - mae: 262.7598 - val_loss: 287.4636 - val_mae: 287.9632\n",
      "Epoch 55/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 260.8086 - mae: 261.3078 - val_loss: 285.9579 - val_mae: 286.4569\n",
      "Epoch 56/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 259.3389 - mae: 259.8379 - val_loss: 284.4213 - val_mae: 284.9205\n",
      "Epoch 57/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 257.8638 - mae: 258.3628 - val_loss: 282.8888 - val_mae: 283.3886\n",
      "Epoch 58/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 256.3597 - mae: 256.8585 - val_loss: 281.2865 - val_mae: 281.7865\n",
      "Epoch 59/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 254.8666 - mae: 255.3652 - val_loss: 279.7269 - val_mae: 280.2269\n",
      "Epoch 60/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 253.3752 - mae: 253.8740 - val_loss: 278.1155 - val_mae: 278.6154\n",
      "Epoch 61/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 251.8451 - mae: 252.3436 - val_loss: 276.4843 - val_mae: 276.9815\n",
      "Epoch 62/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 250.2828 - mae: 250.7807 - val_loss: 274.8609 - val_mae: 275.3602\n",
      "Epoch 63/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 248.7202 - mae: 249.2189 - val_loss: 273.2384 - val_mae: 273.7384\n",
      "Epoch 64/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 247.1397 - mae: 247.6383 - val_loss: 271.6015 - val_mae: 272.1014\n",
      "Epoch 65/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 245.5663 - mae: 246.0647 - val_loss: 269.9934 - val_mae: 270.4934\n",
      "Epoch 66/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 243.9418 - mae: 244.4402 - val_loss: 268.3492 - val_mae: 268.8492\n",
      "Epoch 67/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 242.3616 - mae: 242.8602 - val_loss: 266.7062 - val_mae: 267.2056\n",
      "Epoch 68/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 240.7918 - mae: 241.2904 - val_loss: 265.0942 - val_mae: 265.5942\n",
      "Epoch 69/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 239.2127 - mae: 239.7107 - val_loss: 263.4464 - val_mae: 263.9438\n",
      "Epoch 70/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 237.6266 - mae: 238.1246 - val_loss: 261.7980 - val_mae: 262.2980\n",
      "Epoch 71/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 236.0364 - mae: 236.5348 - val_loss: 260.1129 - val_mae: 260.6129\n",
      "Epoch 72/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 234.4150 - mae: 234.9135 - val_loss: 258.3786 - val_mae: 258.8786\n",
      "Epoch 73/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 232.7958 - mae: 233.2938 - val_loss: 256.7195 - val_mae: 257.2195\n",
      "Epoch 74/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 231.1890 - mae: 231.6873 - val_loss: 255.0426 - val_mae: 255.5419\n",
      "Epoch 75/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 229.5791 - mae: 230.0775 - val_loss: 253.3798 - val_mae: 253.8772\n",
      "Epoch 76/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 227.9455 - mae: 228.4437 - val_loss: 251.6679 - val_mae: 252.1671\n",
      "Epoch 77/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 226.2964 - mae: 226.7945 - val_loss: 249.9526 - val_mae: 250.4521\n",
      "Epoch 78/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 224.6339 - mae: 225.1314 - val_loss: 248.2584 - val_mae: 248.7584\n",
      "Epoch 79/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 223.0313 - mae: 223.5291 - val_loss: 246.6197 - val_mae: 247.1197\n",
      "Epoch 80/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 221.4098 - mae: 221.9081 - val_loss: 244.9559 - val_mae: 245.4559\n",
      "Epoch 81/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 219.7582 - mae: 220.2564 - val_loss: 243.2664 - val_mae: 243.7664\n",
      "Epoch 82/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 218.1243 - mae: 218.6226 - val_loss: 241.5881 - val_mae: 242.0881\n",
      "Epoch 83/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 216.4780 - mae: 216.9763 - val_loss: 239.8446 - val_mae: 240.3446\n",
      "Epoch 84/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 214.8084 - mae: 215.3070 - val_loss: 238.0837 - val_mae: 238.5837\n",
      "Epoch 85/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 213.1717 - mae: 213.6703 - val_loss: 236.3152 - val_mae: 236.8152\n",
      "Epoch 86/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 211.4935 - mae: 211.9922 - val_loss: 234.4900 - val_mae: 234.9894\n",
      "Epoch 87/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 209.8436 - mae: 210.3418 - val_loss: 232.7473 - val_mae: 233.2456\n",
      "Epoch 88/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 208.1967 - mae: 208.6949 - val_loss: 230.9658 - val_mae: 231.4638\n",
      "Epoch 89/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 206.5232 - mae: 207.0214 - val_loss: 229.1733 - val_mae: 229.6711\n",
      "Epoch 90/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 204.8610 - mae: 205.3590 - val_loss: 227.4314 - val_mae: 227.9314\n",
      "Epoch 91/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 203.2196 - mae: 203.7182 - val_loss: 225.7380 - val_mae: 226.2374\n",
      "Epoch 92/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 201.5701 - mae: 202.0690 - val_loss: 224.0715 - val_mae: 224.5715\n",
      "Epoch 93/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 199.9121 - mae: 200.4106 - val_loss: 222.4046 - val_mae: 222.9046\n",
      "Epoch 94/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 198.2644 - mae: 198.7627 - val_loss: 220.7183 - val_mae: 221.2183\n",
      "Epoch 95/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 196.6328 - mae: 197.1314 - val_loss: 219.0193 - val_mae: 219.5191\n",
      "Epoch 96/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 194.9896 - mae: 195.4883 - val_loss: 217.2962 - val_mae: 217.7962\n",
      "Epoch 97/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 193.4134 - mae: 193.9121 - val_loss: 215.6552 - val_mae: 216.1552\n",
      "Epoch 98/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 191.8347 - mae: 192.3334 - val_loss: 213.9438 - val_mae: 214.4438\n",
      "Epoch 99/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 190.2581 - mae: 190.7566 - val_loss: 212.3135 - val_mae: 212.8135\n",
      "Epoch 100/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 188.6922 - mae: 189.1908 - val_loss: 210.6422 - val_mae: 211.1422\n",
      "Epoch 101/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 187.0912 - mae: 187.5896 - val_loss: 208.8954 - val_mae: 209.3954\n",
      "Epoch 102/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 185.4785 - mae: 185.9771 - val_loss: 207.1515 - val_mae: 207.6515\n",
      "Epoch 103/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 183.9033 - mae: 184.4020 - val_loss: 205.3858 - val_mae: 205.8858\n",
      "Epoch 104/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 182.3425 - mae: 182.8410 - val_loss: 203.6614 - val_mae: 204.1613\n",
      "Epoch 105/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 180.7795 - mae: 181.2779 - val_loss: 201.8888 - val_mae: 202.3888\n",
      "Epoch 106/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 179.2277 - mae: 179.7267 - val_loss: 200.0911 - val_mae: 200.5911\n",
      "Epoch 107/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 177.6696 - mae: 178.1682 - val_loss: 198.2788 - val_mae: 198.7788\n",
      "Epoch 108/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 176.0910 - mae: 176.5899 - val_loss: 196.4045 - val_mae: 196.9044\n",
      "Epoch 109/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 174.5422 - mae: 175.0408 - val_loss: 194.6531 - val_mae: 195.1516\n",
      "Epoch 110/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 173.0355 - mae: 173.5344 - val_loss: 193.0436 - val_mae: 193.5436\n",
      "Epoch 111/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 171.5175 - mae: 172.0160 - val_loss: 191.3705 - val_mae: 191.8682\n",
      "Epoch 112/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 170.0204 - mae: 170.5189 - val_loss: 189.7860 - val_mae: 190.2860\n",
      "Epoch 113/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 168.5543 - mae: 169.0531 - val_loss: 188.1817 - val_mae: 188.6807\n",
      "Epoch 114/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 167.0925 - mae: 167.5904 - val_loss: 186.5789 - val_mae: 187.0774\n",
      "Epoch 115/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 165.6183 - mae: 166.1166 - val_loss: 184.9638 - val_mae: 185.4638\n",
      "Epoch 116/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 164.1700 - mae: 164.6684 - val_loss: 183.4182 - val_mae: 183.9174\n",
      "Epoch 117/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 162.7040 - mae: 163.2020 - val_loss: 181.9441 - val_mae: 182.4416\n",
      "Epoch 118/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 161.2693 - mae: 161.7673 - val_loss: 180.5036 - val_mae: 181.0034\n",
      "Epoch 119/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 159.8552 - mae: 160.3531 - val_loss: 179.0905 - val_mae: 179.5894\n",
      "Epoch 120/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 158.5000 - mae: 158.9982 - val_loss: 177.7195 - val_mae: 178.2192\n",
      "Epoch 121/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 157.1624 - mae: 157.6597 - val_loss: 176.2786 - val_mae: 176.7765\n",
      "Epoch 122/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 155.7913 - mae: 156.2895 - val_loss: 174.8603 - val_mae: 175.3598\n",
      "Epoch 123/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 154.4433 - mae: 154.9412 - val_loss: 173.4760 - val_mae: 173.9753\n",
      "Epoch 124/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 153.0804 - mae: 153.5780 - val_loss: 172.0971 - val_mae: 172.5958\n",
      "Epoch 125/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 151.7524 - mae: 152.2502 - val_loss: 170.6993 - val_mae: 171.1982\n",
      "Epoch 126/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 150.4746 - mae: 150.9727 - val_loss: 169.3520 - val_mae: 169.8508\n",
      "Epoch 127/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 149.2410 - mae: 149.7392 - val_loss: 168.0223 - val_mae: 168.5212\n",
      "Epoch 128/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 147.9955 - mae: 148.4937 - val_loss: 166.7281 - val_mae: 167.2265\n",
      "Epoch 129/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 146.7598 - mae: 147.2578 - val_loss: 165.4101 - val_mae: 165.9082\n",
      "Epoch 130/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 145.5455 - mae: 146.0440 - val_loss: 164.1030 - val_mae: 164.6011\n",
      "Epoch 131/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 144.3330 - mae: 144.8308 - val_loss: 162.7926 - val_mae: 163.2905\n",
      "Epoch 132/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 143.1550 - mae: 143.6531 - val_loss: 161.5125 - val_mae: 162.0100\n",
      "Epoch 133/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 141.9612 - mae: 142.4592 - val_loss: 160.3874 - val_mae: 160.8853\n",
      "Epoch 134/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 140.8006 - mae: 141.2985 - val_loss: 159.3050 - val_mae: 159.8024\n",
      "Epoch 135/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 139.6534 - mae: 140.1513 - val_loss: 158.2792 - val_mae: 158.7768\n",
      "Epoch 136/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 138.5126 - mae: 139.0111 - val_loss: 157.2456 - val_mae: 157.7429\n",
      "Epoch 137/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 137.3822 - mae: 137.8805 - val_loss: 156.1706 - val_mae: 156.6682\n",
      "Epoch 138/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 136.3060 - mae: 136.8044 - val_loss: 155.1552 - val_mae: 155.6497\n",
      "Epoch 139/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 135.2488 - mae: 135.7471 - val_loss: 154.2224 - val_mae: 154.7200\n",
      "Epoch 140/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 134.1860 - mae: 134.6840 - val_loss: 153.2765 - val_mae: 153.7740\n",
      "Epoch 141/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 133.1291 - mae: 133.6276 - val_loss: 152.4355 - val_mae: 152.9320\n",
      "Epoch 142/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 132.0785 - mae: 132.5768 - val_loss: 151.5924 - val_mae: 152.0889\n",
      "Epoch 143/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 131.0158 - mae: 131.5140 - val_loss: 150.7442 - val_mae: 151.2384\n",
      "Epoch 144/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 129.9872 - mae: 130.4857 - val_loss: 149.9250 - val_mae: 150.4229\n",
      "Epoch 145/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 128.9701 - mae: 129.4682 - val_loss: 149.1709 - val_mae: 149.6700\n",
      "Epoch 146/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 128.0079 - mae: 128.5053 - val_loss: 148.4985 - val_mae: 148.9972\n",
      "Epoch 147/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 127.0459 - mae: 127.5438 - val_loss: 147.7683 - val_mae: 148.2669\n",
      "Epoch 148/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 126.1527 - mae: 126.6503 - val_loss: 147.0916 - val_mae: 147.5901\n",
      "Epoch 149/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 125.3047 - mae: 125.8024 - val_loss: 146.3597 - val_mae: 146.8581\n",
      "Epoch 150/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 124.4326 - mae: 124.9309 - val_loss: 145.6165 - val_mae: 146.1140\n",
      "Epoch 151/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 123.5753 - mae: 124.0733 - val_loss: 145.0042 - val_mae: 145.5020\n",
      "Epoch 152/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 122.7539 - mae: 123.2528 - val_loss: 144.4098 - val_mae: 144.9071\n",
      "Epoch 153/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 122.0157 - mae: 122.5138 - val_loss: 143.7910 - val_mae: 144.2879\n",
      "Epoch 154/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 121.3034 - mae: 121.8016 - val_loss: 143.2335 - val_mae: 143.7314\n",
      "Epoch 155/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 120.5945 - mae: 121.0926 - val_loss: 142.6833 - val_mae: 143.1811\n",
      "Epoch 156/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 119.9308 - mae: 120.4286 - val_loss: 142.1061 - val_mae: 142.6046\n",
      "Epoch 157/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 119.2926 - mae: 119.7902 - val_loss: 141.5641 - val_mae: 142.0602\n",
      "Epoch 158/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 118.6825 - mae: 119.1803 - val_loss: 141.0311 - val_mae: 141.5292\n",
      "Epoch 159/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 118.0829 - mae: 118.5811 - val_loss: 140.5199 - val_mae: 141.0159\n",
      "Epoch 160/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 117.5011 - mae: 117.9995 - val_loss: 139.9763 - val_mae: 140.4749\n",
      "Epoch 161/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 116.9098 - mae: 117.4082 - val_loss: 139.4218 - val_mae: 139.9204\n",
      "Epoch 162/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 116.3447 - mae: 116.8433 - val_loss: 138.8877 - val_mae: 139.3863\n",
      "Epoch 163/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 115.7987 - mae: 116.2964 - val_loss: 138.3389 - val_mae: 138.8373\n",
      "Epoch 164/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 115.3035 - mae: 115.8015 - val_loss: 137.8132 - val_mae: 138.3121\n",
      "Epoch 165/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 114.8037 - mae: 115.3016 - val_loss: 137.2611 - val_mae: 137.7603\n",
      "Epoch 166/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 114.3370 - mae: 114.8352 - val_loss: 136.7078 - val_mae: 137.2073\n",
      "Epoch 167/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 113.8784 - mae: 114.3765 - val_loss: 136.1640 - val_mae: 136.6637\n",
      "Epoch 168/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 113.4106 - mae: 113.9085 - val_loss: 135.6298 - val_mae: 136.1295\n",
      "Epoch 169/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 112.9678 - mae: 113.4654 - val_loss: 135.0844 - val_mae: 135.5824\n",
      "Epoch 170/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 112.5350 - mae: 113.0330 - val_loss: 134.5614 - val_mae: 135.0611\n",
      "Epoch 171/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 112.1240 - mae: 112.6220 - val_loss: 134.1074 - val_mae: 134.6060\n",
      "Epoch 172/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 111.7504 - mae: 112.2488 - val_loss: 133.6897 - val_mae: 134.1874\n",
      "Epoch 173/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 111.3815 - mae: 111.8797 - val_loss: 133.2329 - val_mae: 133.7313\n",
      "Epoch 174/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 111.0087 - mae: 111.5068 - val_loss: 132.8644 - val_mae: 133.3624\n",
      "Epoch 175/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 110.6584 - mae: 111.1566 - val_loss: 132.5396 - val_mae: 133.0369\n",
      "Epoch 176/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 110.3129 - mae: 110.8107 - val_loss: 132.1837 - val_mae: 132.6811\n",
      "Epoch 177/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 109.9672 - mae: 110.4652 - val_loss: 131.8981 - val_mae: 132.3967\n",
      "Epoch 178/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 109.6487 - mae: 110.1468 - val_loss: 131.6635 - val_mae: 132.1628\n",
      "Epoch 179/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 109.3535 - mae: 109.8511 - val_loss: 131.3782 - val_mae: 131.8777\n",
      "Epoch 180/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 109.0643 - mae: 109.5620 - val_loss: 131.1027 - val_mae: 131.6021\n",
      "Epoch 181/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 108.7834 - mae: 109.2813 - val_loss: 130.8175 - val_mae: 131.3159\n",
      "Epoch 182/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 108.5065 - mae: 109.0039 - val_loss: 130.5210 - val_mae: 131.0198\n",
      "Epoch 183/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 108.2360 - mae: 108.7335 - val_loss: 130.2991 - val_mae: 130.7986\n",
      "Epoch 184/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 107.9801 - mae: 108.4783 - val_loss: 130.0512 - val_mae: 130.5499\n",
      "Epoch 185/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 107.7090 - mae: 108.2071 - val_loss: 129.8114 - val_mae: 130.3104\n",
      "Epoch 186/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 107.4584 - mae: 107.9563 - val_loss: 129.5838 - val_mae: 130.0829\n",
      "Epoch 187/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 107.2059 - mae: 107.7039 - val_loss: 129.3294 - val_mae: 129.8278\n",
      "Epoch 188/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 106.9653 - mae: 107.4632 - val_loss: 129.0736 - val_mae: 129.5726\n",
      "Epoch 189/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 106.7174 - mae: 107.2150 - val_loss: 128.8288 - val_mae: 129.3275\n",
      "Epoch 190/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 106.4962 - mae: 106.9933 - val_loss: 128.5799 - val_mae: 129.0796\n",
      "Epoch 191/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 106.2762 - mae: 106.7741 - val_loss: 128.3377 - val_mae: 128.8373\n",
      "Epoch 192/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 106.0489 - mae: 106.5470 - val_loss: 128.0932 - val_mae: 128.5927\n",
      "Epoch 193/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 105.8188 - mae: 106.3161 - val_loss: 127.8231 - val_mae: 128.3227\n",
      "Epoch 194/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 105.6079 - mae: 106.1060 - val_loss: 127.5953 - val_mae: 128.0941\n",
      "Epoch 195/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 105.3938 - mae: 105.8915 - val_loss: 127.3303 - val_mae: 127.8284\n",
      "Epoch 196/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 105.1831 - mae: 105.6810 - val_loss: 127.0902 - val_mae: 127.5901\n",
      "Epoch 197/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 104.9673 - mae: 105.4648 - val_loss: 126.8579 - val_mae: 127.3578\n",
      "Epoch 198/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 104.7631 - mae: 105.2613 - val_loss: 126.6307 - val_mae: 127.1306\n",
      "Epoch 199/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 104.5595 - mae: 105.0575 - val_loss: 126.4103 - val_mae: 126.9103\n",
      "Epoch 200/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 104.3602 - mae: 104.8581 - val_loss: 126.1690 - val_mae: 126.6690\n",
      "Epoch 201/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 104.1648 - mae: 104.6631 - val_loss: 125.9452 - val_mae: 126.4452\n",
      "Epoch 202/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 103.9663 - mae: 104.4646 - val_loss: 125.7032 - val_mae: 126.2032\n",
      "Epoch 203/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 103.7667 - mae: 104.2646 - val_loss: 125.4585 - val_mae: 125.9585\n",
      "Epoch 204/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 103.5700 - mae: 104.0677 - val_loss: 125.2186 - val_mae: 125.7186\n",
      "Epoch 205/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 103.3785 - mae: 103.8762 - val_loss: 124.9716 - val_mae: 125.4716\n",
      "Epoch 206/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 103.1823 - mae: 103.6800 - val_loss: 124.7531 - val_mae: 125.2531\n",
      "Epoch 207/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 103.0005 - mae: 103.4980 - val_loss: 124.5362 - val_mae: 125.0362\n",
      "Epoch 208/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 102.8209 - mae: 103.3182 - val_loss: 124.3248 - val_mae: 124.8248\n",
      "Epoch 209/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 102.6291 - mae: 103.1267 - val_loss: 124.0832 - val_mae: 124.5832\n",
      "Epoch 210/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 102.4495 - mae: 102.9472 - val_loss: 123.8731 - val_mae: 124.3731\n",
      "Epoch 211/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 102.2633 - mae: 102.7613 - val_loss: 123.6335 - val_mae: 124.1335\n",
      "Epoch 212/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 102.0823 - mae: 102.5799 - val_loss: 123.4264 - val_mae: 123.9264\n",
      "Epoch 213/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 101.9056 - mae: 102.4034 - val_loss: 123.2078 - val_mae: 123.7078\n",
      "Epoch 214/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 101.7383 - mae: 102.2362 - val_loss: 123.0096 - val_mae: 123.5096\n",
      "Epoch 215/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 101.5612 - mae: 102.0595 - val_loss: 122.7760 - val_mae: 123.2760\n",
      "Epoch 216/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 101.3756 - mae: 101.8738 - val_loss: 122.5825 - val_mae: 123.0825\n",
      "Epoch 217/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 101.2050 - mae: 101.7030 - val_loss: 122.3732 - val_mae: 122.8732\n",
      "Epoch 218/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 101.0410 - mae: 101.5389 - val_loss: 122.1661 - val_mae: 122.6661\n",
      "Epoch 219/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 100.8781 - mae: 101.3766 - val_loss: 121.9427 - val_mae: 122.4427\n",
      "Epoch 220/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 100.7158 - mae: 101.2140 - val_loss: 121.7078 - val_mae: 122.2078\n",
      "Epoch 221/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 100.5609 - mae: 101.0596 - val_loss: 121.5144 - val_mae: 122.0144\n",
      "Epoch 222/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 100.3982 - mae: 100.8968 - val_loss: 121.2769 - val_mae: 121.7769\n",
      "Epoch 223/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 100.2451 - mae: 100.7434 - val_loss: 121.0615 - val_mae: 121.5615\n",
      "Epoch 224/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 100.0986 - mae: 100.5966 - val_loss: 120.8515 - val_mae: 121.3515\n",
      "Epoch 225/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 99.9433 - mae: 100.4409 - val_loss: 120.6296 - val_mae: 121.1296\n",
      "Epoch 226/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 99.7929 - mae: 100.2909 - val_loss: 120.4282 - val_mae: 120.9282\n",
      "Epoch 227/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 99.6508 - mae: 100.1491 - val_loss: 120.2353 - val_mae: 120.7353\n",
      "Epoch 228/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 99.4986 - mae: 99.9966 - val_loss: 120.0143 - val_mae: 120.5143\n",
      "Epoch 229/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 99.3509 - mae: 99.8486 - val_loss: 119.7989 - val_mae: 120.2989\n",
      "Epoch 230/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 99.2119 - mae: 99.7102 - val_loss: 119.5870 - val_mae: 120.0870\n",
      "Epoch 231/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 99.0620 - mae: 99.5603 - val_loss: 119.3534 - val_mae: 119.8534\n",
      "Epoch 232/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 98.9162 - mae: 99.4143 - val_loss: 119.1645 - val_mae: 119.6645\n",
      "Epoch 233/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 98.7695 - mae: 99.2676 - val_loss: 118.9576 - val_mae: 119.4576\n",
      "Epoch 234/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 98.6131 - mae: 99.1111 - val_loss: 118.7503 - val_mae: 119.2503\n",
      "Epoch 235/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 98.4607 - mae: 98.9590 - val_loss: 118.5511 - val_mae: 119.0497\n",
      "Epoch 236/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 98.3181 - mae: 98.8161 - val_loss: 118.3500 - val_mae: 118.8492\n",
      "Epoch 237/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 98.1761 - mae: 98.6746 - val_loss: 118.1794 - val_mae: 118.6794\n",
      "Epoch 238/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 98.0392 - mae: 98.5374 - val_loss: 117.9531 - val_mae: 118.4531\n",
      "Epoch 239/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 97.8886 - mae: 98.3866 - val_loss: 117.7828 - val_mae: 118.2828\n",
      "Epoch 240/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 97.7616 - mae: 98.2598 - val_loss: 117.5930 - val_mae: 118.0929\n",
      "Epoch 241/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 97.6266 - mae: 98.1248 - val_loss: 117.4033 - val_mae: 117.9026\n",
      "Epoch 242/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 97.4732 - mae: 97.9707 - val_loss: 117.1903 - val_mae: 117.6885\n",
      "Epoch 243/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 97.3266 - mae: 97.8244 - val_loss: 116.9617 - val_mae: 117.4591\n",
      "Epoch 244/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 97.1834 - mae: 97.6808 - val_loss: 116.7529 - val_mae: 117.2505\n",
      "Epoch 245/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 97.0440 - mae: 97.5410 - val_loss: 116.5456 - val_mae: 117.0444\n",
      "Epoch 246/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 96.9077 - mae: 97.4045 - val_loss: 116.3517 - val_mae: 116.8517\n",
      "Epoch 247/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 96.7607 - mae: 97.2581 - val_loss: 116.1071 - val_mae: 116.6071\n",
      "Epoch 248/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 96.6217 - mae: 97.1189 - val_loss: 115.9221 - val_mae: 116.4194\n",
      "Epoch 249/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 96.4862 - mae: 96.9838 - val_loss: 115.7582 - val_mae: 116.2556\n",
      "Epoch 250/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 96.3589 - mae: 96.8564 - val_loss: 115.5750 - val_mae: 116.0726\n",
      "Epoch 251/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 96.2299 - mae: 96.7275 - val_loss: 115.4161 - val_mae: 115.9148\n",
      "Epoch 252/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 96.1012 - mae: 96.5981 - val_loss: 115.2671 - val_mae: 115.7621\n",
      "Epoch 253/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 95.9694 - mae: 96.4662 - val_loss: 115.1143 - val_mae: 115.6130\n",
      "Epoch 254/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 95.8448 - mae: 96.3417 - val_loss: 114.9683 - val_mae: 115.4681\n",
      "Epoch 255/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 95.7124 - mae: 96.2098 - val_loss: 114.8377 - val_mae: 115.3377\n",
      "Epoch 256/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 95.5794 - mae: 96.0767 - val_loss: 114.7088 - val_mae: 115.2088\n",
      "Epoch 257/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 95.4493 - mae: 95.9460 - val_loss: 114.5762 - val_mae: 115.0762\n",
      "Epoch 258/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 95.3305 - mae: 95.8276 - val_loss: 114.4292 - val_mae: 114.9288\n",
      "Epoch 259/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 95.2188 - mae: 95.7163 - val_loss: 114.3465 - val_mae: 114.8457\n",
      "Epoch 260/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 95.1031 - mae: 95.6000 - val_loss: 114.2524 - val_mae: 114.7520\n",
      "Epoch 261/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 94.9923 - mae: 95.4896 - val_loss: 114.1025 - val_mae: 114.6001\n",
      "Epoch 262/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 94.8737 - mae: 95.3710 - val_loss: 113.9849 - val_mae: 114.4843\n",
      "Epoch 263/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 94.7620 - mae: 95.2596 - val_loss: 113.8808 - val_mae: 114.3807\n",
      "Epoch 264/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 94.6655 - mae: 95.1631 - val_loss: 113.7915 - val_mae: 114.2889\n",
      "Epoch 265/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 94.5566 - mae: 95.0533 - val_loss: 113.7207 - val_mae: 114.2196\n",
      "Epoch 266/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 94.4593 - mae: 94.9567 - val_loss: 113.6037 - val_mae: 114.1021\n",
      "Epoch 267/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 94.3523 - mae: 94.8500 - val_loss: 113.5317 - val_mae: 114.0298\n",
      "Epoch 268/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 94.2500 - mae: 94.7478 - val_loss: 113.4815 - val_mae: 113.9794\n",
      "Epoch 269/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 94.1520 - mae: 94.6499 - val_loss: 113.4035 - val_mae: 113.9000\n",
      "Epoch 270/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 94.0576 - mae: 94.5554 - val_loss: 113.3108 - val_mae: 113.8055\n",
      "Epoch 271/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 93.9549 - mae: 94.4531 - val_loss: 113.2573 - val_mae: 113.7532\n",
      "Epoch 272/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 93.8604 - mae: 94.3586 - val_loss: 113.1513 - val_mae: 113.6503\n",
      "Epoch 273/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 93.7582 - mae: 94.2557 - val_loss: 113.0720 - val_mae: 113.5716\n",
      "Epoch 274/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 93.6649 - mae: 94.1626 - val_loss: 113.0048 - val_mae: 113.5047\n",
      "Epoch 275/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 93.5718 - mae: 94.0695 - val_loss: 112.9345 - val_mae: 113.4343\n",
      "Epoch 276/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 93.4800 - mae: 93.9780 - val_loss: 112.8776 - val_mae: 113.3775\n",
      "Epoch 277/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 93.3890 - mae: 93.8864 - val_loss: 112.8396 - val_mae: 113.3396\n",
      "Epoch 278/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 93.2980 - mae: 93.7960 - val_loss: 112.7894 - val_mae: 113.2894\n",
      "Epoch 279/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 93.2158 - mae: 93.7136 - val_loss: 112.7434 - val_mae: 113.2407\n",
      "Epoch 280/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 93.1331 - mae: 93.6312 - val_loss: 112.6796 - val_mae: 113.1769\n",
      "Epoch 281/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 93.0503 - mae: 93.5482 - val_loss: 112.6453 - val_mae: 113.1453\n",
      "Epoch 282/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.9701 - mae: 93.4679 - val_loss: 112.5664 - val_mae: 113.0656\n",
      "Epoch 283/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.8809 - mae: 93.3789 - val_loss: 112.4939 - val_mae: 112.9939\n",
      "Epoch 284/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.7920 - mae: 93.2897 - val_loss: 112.4535 - val_mae: 112.9535\n",
      "Epoch 285/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.7161 - mae: 93.2138 - val_loss: 112.3886 - val_mae: 112.8886\n",
      "Epoch 286/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.6295 - mae: 93.1276 - val_loss: 112.3128 - val_mae: 112.8128\n",
      "Epoch 287/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 92.5543 - mae: 93.0526 - val_loss: 112.2674 - val_mae: 112.7672\n",
      "Epoch 288/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.4814 - mae: 92.9793 - val_loss: 112.2063 - val_mae: 112.7060\n",
      "Epoch 289/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.4114 - mae: 92.9092 - val_loss: 112.1661 - val_mae: 112.6660\n",
      "Epoch 290/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.3501 - mae: 92.8481 - val_loss: 112.1259 - val_mae: 112.6252\n",
      "Epoch 291/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.2767 - mae: 92.7745 - val_loss: 112.0820 - val_mae: 112.5776\n",
      "Epoch 292/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.2133 - mae: 92.7111 - val_loss: 112.0354 - val_mae: 112.5340\n",
      "Epoch 293/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.1450 - mae: 92.6430 - val_loss: 111.9911 - val_mae: 112.4905\n",
      "Epoch 294/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.0805 - mae: 92.5779 - val_loss: 111.9563 - val_mae: 112.4553\n",
      "Epoch 295/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 92.0109 - mae: 92.5091 - val_loss: 111.8952 - val_mae: 112.3939\n",
      "Epoch 296/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.9461 - mae: 92.4437 - val_loss: 111.8295 - val_mae: 112.3270\n",
      "Epoch 297/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.8860 - mae: 92.3837 - val_loss: 111.7593 - val_mae: 112.2573\n",
      "Epoch 298/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.8284 - mae: 92.3261 - val_loss: 111.7363 - val_mae: 112.2337\n",
      "Epoch 299/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.7622 - mae: 92.2596 - val_loss: 111.6713 - val_mae: 112.1679\n",
      "Epoch 300/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.6995 - mae: 92.1967 - val_loss: 111.6267 - val_mae: 112.1229\n",
      "Epoch 301/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.6361 - mae: 92.1330 - val_loss: 111.6173 - val_mae: 112.1122\n",
      "Epoch 302/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.5740 - mae: 92.0712 - val_loss: 111.6117 - val_mae: 112.1058\n",
      "Epoch 303/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.5171 - mae: 92.0145 - val_loss: 111.5574 - val_mae: 112.0527\n",
      "Epoch 304/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.4588 - mae: 91.9559 - val_loss: 111.5266 - val_mae: 112.0225\n",
      "Epoch 305/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.4040 - mae: 91.9006 - val_loss: 111.4874 - val_mae: 111.9831\n",
      "Epoch 306/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.3446 - mae: 91.8417 - val_loss: 111.4374 - val_mae: 111.9334\n",
      "Epoch 307/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.2897 - mae: 91.7865 - val_loss: 111.3693 - val_mae: 111.8658\n",
      "Epoch 308/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.2328 - mae: 91.7299 - val_loss: 111.2895 - val_mae: 111.7860\n",
      "Epoch 309/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.1858 - mae: 91.6828 - val_loss: 111.2439 - val_mae: 111.7407\n",
      "Epoch 310/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.1277 - mae: 91.6248 - val_loss: 111.1894 - val_mae: 111.6861\n",
      "Epoch 311/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.0794 - mae: 91.5763 - val_loss: 111.1693 - val_mae: 111.6661\n",
      "Epoch 312/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 91.0283 - mae: 91.5248 - val_loss: 111.1021 - val_mae: 111.6003\n",
      "Epoch 313/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 90.9727 - mae: 91.4696 - val_loss: 111.0653 - val_mae: 111.5624\n",
      "Epoch 314/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.9249 - mae: 91.4219 - val_loss: 110.9724 - val_mae: 111.4692\n",
      "Epoch 315/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.8681 - mae: 91.3653 - val_loss: 110.9164 - val_mae: 111.4133\n",
      "Epoch 316/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.8269 - mae: 91.3241 - val_loss: 110.8813 - val_mae: 111.3781\n",
      "Epoch 317/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.7774 - mae: 91.2747 - val_loss: 110.8165 - val_mae: 111.3136\n",
      "Epoch 318/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.7296 - mae: 91.2267 - val_loss: 110.7668 - val_mae: 111.2637\n",
      "Epoch 319/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.6814 - mae: 91.1785 - val_loss: 110.7070 - val_mae: 111.2039\n",
      "Epoch 320/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.6367 - mae: 91.1341 - val_loss: 110.6433 - val_mae: 111.1403\n",
      "Epoch 321/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.5911 - mae: 91.0887 - val_loss: 110.5779 - val_mae: 111.0760\n",
      "Epoch 322/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.5421 - mae: 91.0398 - val_loss: 110.5330 - val_mae: 111.0298\n",
      "Epoch 323/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.4931 - mae: 90.9910 - val_loss: 110.4870 - val_mae: 110.9841\n",
      "Epoch 324/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.4491 - mae: 90.9471 - val_loss: 110.4159 - val_mae: 110.9128\n",
      "Epoch 325/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.4016 - mae: 90.8998 - val_loss: 110.4076 - val_mae: 110.9045\n",
      "Epoch 326/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.3573 - mae: 90.8544 - val_loss: 110.3508 - val_mae: 110.8475\n",
      "Epoch 327/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.3087 - mae: 90.8069 - val_loss: 110.3220 - val_mae: 110.8193\n",
      "Epoch 328/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.2681 - mae: 90.7662 - val_loss: 110.2195 - val_mae: 110.7168\n",
      "Epoch 329/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.2130 - mae: 90.7109 - val_loss: 110.1902 - val_mae: 110.6867\n",
      "Epoch 330/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.1732 - mae: 90.6712 - val_loss: 110.1322 - val_mae: 110.6292\n",
      "Epoch 331/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.1298 - mae: 90.6273 - val_loss: 110.0968 - val_mae: 110.5937\n",
      "Epoch 332/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.0865 - mae: 90.5849 - val_loss: 110.0259 - val_mae: 110.5228\n",
      "Epoch 333/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.0412 - mae: 90.5392 - val_loss: 109.9408 - val_mae: 110.4369\n",
      "Epoch 334/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 90.0004 - mae: 90.4984 - val_loss: 109.8862 - val_mae: 110.3827\n",
      "Epoch 335/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.9632 - mae: 90.4607 - val_loss: 109.8444 - val_mae: 110.3409\n",
      "Epoch 336/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.9230 - mae: 90.4211 - val_loss: 109.8088 - val_mae: 110.3050\n",
      "Epoch 337/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 89.8787 - mae: 90.3759 - val_loss: 109.7877 - val_mae: 110.2838\n",
      "Epoch 338/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 89.8464 - mae: 90.3438 - val_loss: 109.7606 - val_mae: 110.2567\n",
      "Epoch 339/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 89.8096 - mae: 90.3075 - val_loss: 109.7503 - val_mae: 110.2453\n",
      "Epoch 340/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.7738 - mae: 90.2716 - val_loss: 109.7085 - val_mae: 110.2054\n",
      "Epoch 341/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.7419 - mae: 90.2398 - val_loss: 109.6920 - val_mae: 110.1900\n",
      "Epoch 342/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.7030 - mae: 90.2008 - val_loss: 109.6327 - val_mae: 110.1300\n",
      "Epoch 343/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 89.6691 - mae: 90.1671 - val_loss: 109.6033 - val_mae: 110.0997\n",
      "Epoch 344/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 89.6370 - mae: 90.1347 - val_loss: 109.5844 - val_mae: 110.0814\n",
      "Epoch 345/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.6066 - mae: 90.1046 - val_loss: 109.5729 - val_mae: 110.0710\n",
      "Epoch 346/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.5704 - mae: 90.0687 - val_loss: 109.5305 - val_mae: 110.0292\n",
      "Epoch 347/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.5392 - mae: 90.0368 - val_loss: 109.4738 - val_mae: 109.9732\n",
      "Epoch 348/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.5082 - mae: 90.0061 - val_loss: 109.4448 - val_mae: 109.9442\n",
      "Epoch 349/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.4685 - mae: 89.9659 - val_loss: 109.3962 - val_mae: 109.8942\n",
      "Epoch 350/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.4414 - mae: 89.9392 - val_loss: 109.3853 - val_mae: 109.8834\n",
      "Epoch 351/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.4017 - mae: 89.8998 - val_loss: 109.3544 - val_mae: 109.8508\n",
      "Epoch 352/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.3768 - mae: 89.8752 - val_loss: 109.3338 - val_mae: 109.8299\n",
      "Epoch 353/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.3398 - mae: 89.8377 - val_loss: 109.3009 - val_mae: 109.7976\n",
      "Epoch 354/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.3092 - mae: 89.8068 - val_loss: 109.2483 - val_mae: 109.7463\n",
      "Epoch 355/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 89.2753 - mae: 89.7731 - val_loss: 109.2206 - val_mae: 109.7165\n",
      "Epoch 356/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 89.2455 - mae: 89.7428 - val_loss: 109.1677 - val_mae: 109.6636\n",
      "Epoch 357/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 89.2201 - mae: 89.7180 - val_loss: 109.1526 - val_mae: 109.6482\n",
      "Epoch 358/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 89.1838 - mae: 89.6814 - val_loss: 109.1067 - val_mae: 109.6040\n",
      "Epoch 359/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.1589 - mae: 89.6568 - val_loss: 109.0806 - val_mae: 109.5761\n",
      "Epoch 360/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.1292 - mae: 89.6266 - val_loss: 109.0608 - val_mae: 109.5562\n",
      "Epoch 361/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.1032 - mae: 89.6010 - val_loss: 109.0214 - val_mae: 109.5167\n",
      "Epoch 362/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.0738 - mae: 89.5720 - val_loss: 109.0051 - val_mae: 109.5004\n",
      "Epoch 363/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.0457 - mae: 89.5437 - val_loss: 109.0006 - val_mae: 109.4980\n",
      "Epoch 364/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 89.0164 - mae: 89.5141 - val_loss: 108.9847 - val_mae: 109.4817\n",
      "Epoch 365/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.9860 - mae: 89.4835 - val_loss: 108.9625 - val_mae: 109.4591\n",
      "Epoch 366/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.9686 - mae: 89.4659 - val_loss: 108.9331 - val_mae: 109.4275\n",
      "Epoch 367/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.9402 - mae: 89.4379 - val_loss: 108.8884 - val_mae: 109.3844\n",
      "Epoch 368/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 88.9164 - mae: 89.4141 - val_loss: 108.8762 - val_mae: 109.3717\n",
      "Epoch 369/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 88.8867 - mae: 89.3846 - val_loss: 108.8461 - val_mae: 109.3417\n",
      "Epoch 370/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 88.8671 - mae: 89.3649 - val_loss: 108.8194 - val_mae: 109.3149\n",
      "Epoch 371/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.8383 - mae: 89.3364 - val_loss: 108.7850 - val_mae: 109.2784\n",
      "Epoch 372/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.8227 - mae: 89.3207 - val_loss: 108.7603 - val_mae: 109.2539\n",
      "Epoch 373/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.7916 - mae: 89.2898 - val_loss: 108.7349 - val_mae: 109.2287\n",
      "Epoch 374/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.7713 - mae: 89.2690 - val_loss: 108.7145 - val_mae: 109.2090\n",
      "Epoch 375/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.7465 - mae: 89.2444 - val_loss: 108.6896 - val_mae: 109.1848\n",
      "Epoch 376/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 88.7233 - mae: 89.2209 - val_loss: 108.6572 - val_mae: 109.1517\n",
      "Epoch 377/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.7005 - mae: 89.1983 - val_loss: 108.6566 - val_mae: 109.1521\n",
      "Epoch 378/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.6762 - mae: 89.1738 - val_loss: 108.6327 - val_mae: 109.1292\n",
      "Epoch 379/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.6555 - mae: 89.1529 - val_loss: 108.6167 - val_mae: 109.1133\n",
      "Epoch 380/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.6320 - mae: 89.1299 - val_loss: 108.5776 - val_mae: 109.0733\n",
      "Epoch 381/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.6126 - mae: 89.1103 - val_loss: 108.5223 - val_mae: 109.0163\n",
      "Epoch 382/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.5909 - mae: 89.0888 - val_loss: 108.4897 - val_mae: 108.9846\n",
      "Epoch 383/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.5691 - mae: 89.0668 - val_loss: 108.4544 - val_mae: 108.9456\n",
      "Epoch 384/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.5533 - mae: 89.0510 - val_loss: 108.4254 - val_mae: 108.9169\n",
      "Epoch 385/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.5310 - mae: 89.0285 - val_loss: 108.4233 - val_mae: 108.9155\n",
      "Epoch 386/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.5113 - mae: 89.0088 - val_loss: 108.3976 - val_mae: 108.8897\n",
      "Epoch 387/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.4921 - mae: 88.9897 - val_loss: 108.3837 - val_mae: 108.8769\n",
      "Epoch 388/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.4693 - mae: 88.9671 - val_loss: 108.3577 - val_mae: 108.8498\n",
      "Epoch 389/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.4584 - mae: 88.9564 - val_loss: 108.3379 - val_mae: 108.8314\n",
      "Epoch 390/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.4324 - mae: 88.9298 - val_loss: 108.3245 - val_mae: 108.8177\n",
      "Epoch 391/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.4148 - mae: 88.9126 - val_loss: 108.3032 - val_mae: 108.7984\n",
      "Epoch 392/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.4018 - mae: 88.8997 - val_loss: 108.2701 - val_mae: 108.7654\n",
      "Epoch 393/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.3760 - mae: 88.8737 - val_loss: 108.2487 - val_mae: 108.7419\n",
      "Epoch 394/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.3618 - mae: 88.8594 - val_loss: 108.2368 - val_mae: 108.7319\n",
      "Epoch 395/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.3438 - mae: 88.8411 - val_loss: 108.2284 - val_mae: 108.7244\n",
      "Epoch 396/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.3225 - mae: 88.8199 - val_loss: 108.2134 - val_mae: 108.7099\n",
      "Epoch 397/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.3117 - mae: 88.8092 - val_loss: 108.1773 - val_mae: 108.6733\n",
      "Epoch 398/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.2906 - mae: 88.7881 - val_loss: 108.1723 - val_mae: 108.6680\n",
      "Epoch 399/400\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 88.2733 - mae: 88.7710 - val_loss: 108.1597 - val_mae: 108.6543\n",
      "Epoch 400/400\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 88.2504 - mae: 88.7484 - val_loss: 108.1575 - val_mae: 108.6516\n"
     ]
    }
   ],
   "source": [
    "# Inicia o treinamento da rede\n",
    "redes_treinadas = neuralNetwork.fit(train_x, train_y, epochs = 400, batch_size = 32, validation_data = (validation_x, validation_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108.65160369873047\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imprime o menor erro absoluto médio encontrado\n",
    "print(min(neuralNetwork.history.history['val_mae']))\n",
    "\n",
    "# Plota o gráfico de convegência do treinamento\n",
    "plt.plot(neuralNetwork.history.history['val_mae'])\n",
    "plt.title('Histórico de Treinamento')\n",
    "plt.ylabel('Erro Absoluto')\n",
    "plt.xlabel('Épocas de treinamento')\n",
    "plt.legend(['Rede Componentes Principais'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 884us/step\n"
     ]
    }
   ],
   "source": [
    "# Insere os valores de teste na rede e coleta os resultados gerados pela rede\n",
    "predicts = neuralNetwork.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.246369026802682, 18.455534951324307, 3.777939589707168, 5.578123791383045]\n",
      "[1.013952813900522, None, 174.89212835842852, 181.71215318653682]\n",
      "[None, 35.332103414655776, 56.57989397354719, 17.84115687073001]\n",
      "[437.4779652074441, 459.35480773105735, 750.6486286488614, 85.4899169921875]\n",
      "[41.509485094329165, 11.525522838284422, 8.128592590567688, 9.866504279934631]\n",
      "[78.61497281379266, 70.79862095458701, 21.009763607308884, 29.35626942624328]\n",
      "[4.341339901577666, 6.530352616968692, 6.263867804949469, 33.332147813381106]\n",
      "[75.73453198096618, 264.0148043943174, 45.161612795097234, 4.123122542774703]\n",
      "[None, 22.853414153492974, 15.951287591930678, 33.39577326698909]\n",
      "[None, 349.28863073475264, 84.10506026274284, 4.495875040690104]\n",
      "[0.3898792255552901, 500.47046889921336, 22.353004242922953, 2.3785581683168315]\n",
      "[10.033462643532113, 11.852434796855697, 20.762421864108596, 10.235968975981406]\n",
      "[25.1939457677559, 88.29700943931881, 78.73600295666205, 0.2591024521221532]\n",
      "[28.383879228071734, 118.45916490479516, 15.314326231342049, 56.1118905402754]\n",
      "[9.321259920042174, 78.27886061762749, 175.59638520302104, 25.960200493324532]\n",
      "[None, 24.01317157662665, 62.339558265412556, 8.07384364652318]\n",
      "[13.393419511827908, 96.3578425530716, 18.60414105115362, 0.6305977957589286]\n",
      "[187.1189375987764, 111.11703984106529, 38.80761043331672, 4.58675160975898]\n",
      "[20.994453878005768, 4.465032870328624, 8.126115363261421, 14.303482970228707]\n",
      "[11.66202712631504, 46.723007651276646, 26.536706213596624, 3.4921482631138394]\n",
      "[31.49477044795141, 135.3859619936083, 48.10186538099096, 21.792782054227942]\n",
      "[72.84002572178362, 11.943037479669034, 5.649405069778242, 125.34611095081675]\n",
      "[63.388216377484916, 44.87809499104818, 14.16847239073499, 4.619384079836728]\n",
      "[49.8675814660363, 31.980714475869014, 43.71584159499533, 30.36899409018272]\n",
      "[None, 43.97803727570954, 29.73923020111295, 90.43850228806173]\n",
      "[112.78965883551275, 10.762281993027738, 7.019492920386415, 9.567476098590792]\n",
      "[43.730119374699285, 43.19203433671526, 29.524617615845443, 3.78910277348194]\n",
      "[52.71393082567608, 13.325928283600689, 15.62236430757888, 14.252450612670216]\n",
      "[37.683134043261354, 6.842222133675626, 8.20272179795059, 9.674755252275755]\n",
      "[88.77832909724582, 31.29300457832943, 30.68824380905049, 14.677712617627229]\n",
      "[90.98067039552251, 94.44297866880021, 70.76120114731255, 12.818661414587451]\n",
      "[None, None, 420.59858416290564, 20.845576695033483]\n",
      "[81.9724239643541, 61.87355224159761, 41.51782638514826, 23.379622727152245]\n",
      "[None, 84.08591099984916, 5.327845481663977, 9.413263334644784]\n",
      "[85.26619903118083, 12.229749666665972, 3.7837070326682873, 2.966006989596879]\n",
      "[33.12741105772202, 252.1534837927992, 50.87584007760151, 11.99267625347558]\n",
      "[64.42716380475692, 16.897312775263202, 327.56771113413174, 25.44811986340307]\n",
      "[None, 48.059329001790715, 13.435065350409364, 14.422569179295897]\n",
      "[101.63425837948618, 52.96772789843247, 42.748231124609624, 4.693913459777832]\n",
      "[63.03398322578104, 28.132239330970044, 33.24807535076655, 5.739802264148521]\n",
      "[39.62481394285887, 60.14190122710505, 27.582786804272498, 14.376222547087425]\n",
      "[24.41279989890133, 40.90518733923774, 12.663794924264677, 19.659370983833874]\n",
      "[69.11271573448717, 21.309687784035305, 62.216632779786885, 28.424184698807565]\n",
      "[68.90001954524023, 130.7723166926237, 0.6191726753581746, 8.825269398707587]\n",
      "[53.25290371912605, 24.45587593418915, 30.262574250521357, 11.024381328561454]\n",
      "[10.950897364289556, 64.6895718599987, 10.544256110510895, 1.691581107474662]\n",
      "[82.19402646986707, 49.012518369860494, 17.495240836307925, 10.402099609375]\n",
      "[46.50264303167383, 109.13966880137369, 2.890068293149644, 98.72357869885631]\n",
      "[22.833136031983216, 520.0594135257073, 47.851139414782494, 22.993877994061187]\n",
      "[58.55780549392634, 39.37551247296594, 33.46016961543084, 17.005621526659148]\n",
      "[67.96436487447018, 30.446541914131565, 10.395798096421025, 10.32317589069235]\n",
      "[50.50443707811789, 34.39203253346444, 23.48545123099553, 6.467162731081941]\n",
      "[None, 30.816276807650134, 7.990987589882505, 12.271703309365781]\n",
      "[61.3899461423323, 78.39258431812307, 37.21133256314901, 4.999292197347689]\n",
      "[None, 1.546129918279031, 39.01807400129195, 13.271494959131141]\n",
      "[5.3325616183548465, 69.60668725118025, 27.51909500243804, 38.140616232518994]\n",
      "[4.540038789259228, 26.34831839184927, 24.469452657997103, 8.933717830251783]\n",
      "[0.9452413525101754, 20.202600295383103, 15.676470762118994, 21.583813209874627]\n",
      "[17.701885866269613, 21.947675698851647, 11.149436325937994, 20.750126953125]\n",
      "[19.515484444067894, 41.605030638432545, 16.214194830372662, 2.401845634714317]\n",
      "[None, 115.28124093150063, 18.37174780794322, 54.13531833224826]\n",
      "[None, 28.183809013249927, 38.78708913654624, 9.009376201586969]\n",
      "[19.495617176785633, 46.75970419852189, 49.724618819233015, 0.6084382697926214]\n",
      "[54.20176577689785, 33.860381728927145, 41.95732135710363, 30.835484542553615]\n",
      "[80.75795387852729, 13.68855132791918, 16.376059082588903, 3.7905786244292234]\n",
      "[6.413945904184947, 25.736625744153475, 36.7313070282195, 11.470326100747416]\n",
      "[9.671618326854588, 71.3163436842707, 6.494244222189844, 15.908682953315937]\n",
      "[0.6245651739729486, 6.103815698016755, 21.22012036574772, 19.68890227724574]\n",
      "[41.26158597176535, 5.397507798956641, 1.307761647823627, 39.90127029122082]\n",
      "[59.34715164155748, 26.34076351029987, 15.692724778851714, 33.390036190257355]\n",
      "[66.36408218587103, 156.93820238651597, 29.33140529644826, 20.347005457965874]\n",
      "[68.91552101784337, 36.597114696837316, 48.390880422382196, 41.4880151147241]\n",
      "[41.1297251319646, 22.22740695389649, 17.456913550884774, 1.8037341889880951]\n",
      "[None, 229.4081436960321, 59.59161096520547, 6.311739408052884]\n",
      "[69.80675307610376, 66.08355780436447, 13.18063314023965, 14.038873226084608]\n",
      "[47.31013092175454, 59.36638631340004, 4.501701514694042, 35.20176478794642]\n",
      "[65.57084477686212, 50.96918967450227, 103.03388301205871, 13.143142219733987]\n",
      "[61.97543951074715, 21.10614671340325, 1.5880270194569315, 12.375619699899417]\n",
      "[None, 44.41181835914922, 42.505612131952624, 14.652250083859938]\n",
      "[58.58091308974773, 23.731127466805418, 20.658580817930652, 13.588649342908527]\n",
      "[None, 108.9765016816649, 70.1650535291971, 26.482945103799143]\n",
      "[29.33916928145685, 34.84807372204657, 15.37581686116286, 17.21955503426119]\n",
      "[6.466517185448287, 30.233878630327983, 20.89536943528546, 7.13105232484879]\n",
      "[41.914734124094174, 5.055026069801208, 8.581167457899047, 31.816964611289382]\n",
      "[80.02538417817495, 26.544246958345415, 12.558218367367594, 7.879302257627953]\n",
      "[316.32911780361457, 85.99576544043678, 1.9691982735385722, 26.38642177554809]\n",
      "[69.72534132982673, 26.78448882814955, 24.354413950354797, 24.633283760552832]\n",
      "[None, 11.228554071539524, 31.744092983918666, 34.02080276972568]\n",
      "[51.620103597756895, 175.71909439160626, 48.689828429092, 23.46297744350388]\n",
      "[84.63852503987493, 104.37744140625, 91.01247645255722, 16.048670179061308]\n",
      "[45.40023892797749, 19.446611630842174, 12.365825693158419, 93.22067032999067]\n",
      "[70.39635386291381, 3.379473000380942, 13.117858674052702, 10.997051319388168]\n",
      "[49.244313254042225, None, 1720.581044540342, 158.0259753811744]\n",
      "[310.1971741031226, 17.605779686051584, 59.69502128421049, 20.95077302720812]\n",
      "[583.931577391699, 195.583698212041, 30.610389662177077, 11.970200994605957]\n",
      "[83.26227022545217, 16.353730366058556, 12.551425315203266, 21.71604909053465]\n",
      "[7.483837610141364, 14.966585964723192, 11.410182174936592, 2.4551374122995417]\n",
      "[65.20331850467502, 29.867405086368702, 54.25432064152346, 33.365325676354]\n",
      "[82.24734755820332, 42.69402798247979, 120.18756394280152, 6.11419677734375]\n",
      "[31.316953152418137, 55.942500108343715, 44.95049872199056, 16.644568810096153]\n",
      "[21.379138936414638, 55.50917915859041, 145.75444616707287, 7.954241892637638]\n",
      "[22.69802101838531, 17.30851826453513, 6.900080871654603, 17.954950372994535]\n",
      "[None, 29.927207434263263, 64.01937954177347, 33.06014591860831]\n",
      "[81.88802457553763, 280.43082113295566, 5.2487907968790815, 39.051732040385986]\n",
      "[17.984149125014373, 78.02036541020225, 4.974899129339554, 3.278430540170243]\n",
      "[None, 27.234363440869075, 13.887305860002948, 2.784406524343589]\n",
      "[35.06336493893599, 52.77745955222588, 0.7951312168428895, 25.75017675499007]\n",
      "[21.205304335908878, 68.46607434329285, 161.95463327504666, 4.400848110396086]\n",
      "[58.693492603918294, 36.63660492194294, 32.86512080330436, 9.56895877908028]\n",
      "[70.36616592218313, 39.553675445553715, 43.28027063501521, 8.400712933456688]\n",
      "[54.84948462111118, 48.54223077947443, 7.745015756317293, 64.1890469719382]\n",
      "[7.5745702040120335, 31.046806083427175, 4.688968022907892, 19.135419060202207]\n",
      "[None, 4.988981066558491, 20.719850784448177, 26.588736924549078]\n",
      "[59.469327541777794, 29.27702332306843, 2.22299059911949, 9.592446128090659]\n",
      "[64.32856828248192, 18.824363178193185, 8.217116215664449, 11.854976841776926]\n",
      "[47.23388146334759, 32.96979035951079, 5.557246720275458, 21.3714599609375]\n",
      "[128.37037875303864, 24.13984698545232, 47.29470748997338, 0.4678617080234554]\n",
      "[80.0414168831244, 139.32136257552497, 33.985858670848096, 13.407259460882093]\n",
      "[12.157779982110034, 15.808754343912538, 47.192892221906476, 4.989030969287703]\n",
      "[132.57355157639228, 57.50334555294806, 48.40611525572063, 16.776521609780566]\n",
      "[88.76083066504657, 117.0333952646837, 6.669343566161283, 25.39935376270708]\n",
      "[24.318437142805617, 37.94066263428817, 11.472392181951678, 17.38157620395187]\n",
      "[89.7874092834175, 9.957428854085165, 13.793472841638573, 0.1141577216066482]\n",
      "[43.809472360918605, 88.6702672689451, 10.645634451666682, 34.08316276325654]\n",
      "[22.334405578875987, 39.70744233188977, 175.11299048940475, 5.79382560920187]\n",
      "[82.19295937169694, 56.94815255947011, 32.77356934731519, 3.8147460157498]\n",
      "[None, 394.55832657455767, 4.561799337788997, 10.385035868710691]\n",
      "[53.83976710002827, 54.78943340089001, 24.978431566794683, 6.09931241239281]\n",
      "[95.29089397542842, 138.5691385817336, 6.212937045747085, 1.9501232710040985]\n",
      "[None, 45.253001173881636, 16.513421393801913, 5.185602999281609]\n",
      "[None, 72.35337656646634, 64.71385421944535, 21.184496903947508]\n",
      "[15.990713825376012, 9.487573476601684, 9.80350785554081, 7.964546660072783]\n",
      "[87.68295474245502, 61.087886622694676, 59.806982952615485, 8.907674153645834]\n",
      "[None, 26.216346730067958, 105.11092059553975, 20.622981310733216]\n",
      "[44.287520522166716, 183.59671526538236, 40.07771040295815, 2.5690159534459243]\n",
      "[84.99721033736395, 52.74854408256915, 41.741274262318655, 8.568322064472591]\n"
     ]
    }
   ],
   "source": [
    "errorPercentage = []\n",
    "\n",
    "# Calculo do tamanho do erro\n",
    "for i in range(test_y.shape[0]):\n",
    "    errorPercentage.append([])\n",
    "\n",
    "    for j in range(test_y.shape[1]):\n",
    "        erro = fabs(predicts[i][j] - test_y.iloc[i,j]) # Calcula o módulo da diferença entre o valor real e o gerado pela rede\n",
    "\n",
    "        if test_y.iloc[i,j] != 0: # Verifica se o valor real é diferente de zero para evitar divisão por zero\n",
    "            errorPercentage[i].append((erro / test_y.iloc[i,j])*100) # Calcula a porcentagem do tamanho do erro em relaçao ao valor real\n",
    "\n",
    "        else:\n",
    "            errorPercentage[i].append(None)  # Substitui a porcentagem com um valor nulo para ser descartado\n",
    "\n",
    "# Exibe o resultado\n",
    "for i in errorPercentage:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média do Erro em Porcetagem\n",
      "DOMPRECDOMEXP: 63.23%\n",
      "ADENSEXCDOMEXP: 70.11%\n",
      "ONUSEXCDOMEXP: 56.30%\n",
      "COABFAMDOMEXP: 21.05%\n"
     ]
    }
   ],
   "source": [
    "meanErrorPercentage = []\n",
    "\n",
    "# Calcula a média das porcentagens excluindo os valores nulos\n",
    "for i in range(test_y.shape[1]):\n",
    "    sum = 0\n",
    "    counter = test_y.shape[0]\n",
    "\n",
    "    for j in range(test_y.shape[0]):\n",
    "        if errorPercentage[j][i] == None:\n",
    "            counter -= 1\n",
    "\n",
    "        else:\n",
    "            sum += errorPercentage[j][i]\n",
    "\n",
    "    meanErrorPercentage.append(sum/counter)\n",
    "\n",
    "print(\"Média do Erro em Porcetagem\")\n",
    "for i in range(len(meanErrorPercentage)):\n",
    "    print(\"{}: {:.2f}%\".format(saidasDomicilios[i], meanErrorPercentage[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
